{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# spaCy & NLTK\n",
        "## __spaCy__ is Object Oriented whereas __NLTK__ is string processing library\n",
        "## __spaCy__ provides most efficient NLP algorithm for a given task. Hence if we care about the end result, we should go with __spaCy__ whereas __NLTK__ provides access to many algorithms. If we care about algorithm and customizations, we should go with __NLTK__.\n",
        "## __spaCy__ is user-friendly whereas __NLTK__ is also user-friendly but probably less-user friendly as compared to __spaCy__.\n",
        "## __spaCy__ is new library and has a very active user community whereas __NLTK__ is old library and has user community as active as __spaCy__."
      ],
      "metadata": {
        "id": "nWHr1O5LEbLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65AP5IMhFmlx",
        "outputId": "0e5d70b5-5442-4b5f-c1df-82b1de85239b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\") # Downloading the english package i.e 'en_core_web_sm' of spacy\n",
        "# We need to show why spacy is object oriented\n",
        "doc = nlp(\"Dr. Strange loves pav bhaji of Mumbai. Hulk loves chaat of Delhi.\")\n",
        "# Here it has 2 sentences\n",
        "for sentence in doc.sents:\n",
        "  print(sentence)\n",
        "# In doc.sents it is aware that 'Dr.' is not a sentence of itself rather it's a part of that 1st sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHwgdrAlFrcz",
        "outputId": "9fdfaf56-9e09-4ac2-ace1-5f109795a150"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji of Mumbai.\n",
            "Hulk loves chaat of Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is basically called __Sentence Tokenization__ in spaCy. And we can see we created a doc object where we define its sents property and it gives us sentences in tokenize form."
      ],
      "metadata": {
        "id": "4E9cOk_iG7_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:\n",
        "  for word in sentence:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJp5UkCgGvqi",
        "outputId": "e035c942-2d89-4b33-914e-13a676a86844"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "Mumbai\n",
            ".\n",
            "Hulk\n",
            "loves\n",
            "chaat\n",
            "of\n",
            "Delhi\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we can see the __Word Tokenization__. Now let's do the same thing in NLTK."
      ],
      "metadata": {
        "id": "FYTPMgHHMTX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # Downloading the default package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5IYg8d1MRp9",
        "outputId": "5ba83234-ea55-4a86-931b-54554b050eca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## There are lots of tokenizer in NLTK:\n",
        "## api, blankline_tokenize, BlanklineTokenizer, casual, casual_tokenize, destructive, legality_principle, legalitySyllableTokenizer, line_tokenize, LineTokenizer, etc."
      ],
      "metadata": {
        "id": "Pmt0MPBSNWie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokenize(\"Dr. Strange loves pav bhaji of Mumbai. Hulk loves chaat of Delhi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4dozEKuMgSi",
        "outputId": "70c9d74f-5a24-44be-ee11-765d2afa3627"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr.', 'Strange loves pav bhaji of Mumbai.', 'Hulk loves chaat of Delhi.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here, it didn't work well because it's saying 'Dr.' is a separate sentence which we don't want. Here, we can see it's a string processing library means we  give string as an input and we get string as an output."
      ],
      "metadata": {
        "id": "0uVvE0p0OlVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokenize(\"Dr. Strange loves pav bhaji of Mumbai. Hulk loves chaat of Delhi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SQNrD1kOgzO",
        "outputId": "0e4fe7ca-db87-4341-ce12-dc8634ecae85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr',\n",
              " '.',\n",
              " 'Strange',\n",
              " 'loves',\n",
              " 'pav',\n",
              " 'bhaji',\n",
              " 'of',\n",
              " 'Mumbai',\n",
              " '.',\n",
              " 'Hulk',\n",
              " 'loves',\n",
              " 'chaat',\n",
              " 'of',\n",
              " 'Delhi',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## It's not like NLTK is not powerful or appropriate library; it can be really powerful library cuz it's used in production in big companies but we need to modify and customize this library to satisy our needs whereas spaCy out of the box gives us the best algorithm and it works efficiently."
      ],
      "metadata": {
        "id": "3ItysqFlPcdI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iAF8Dx-rPR4L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}